{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a6f7cf5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Programação Genética - Trabalho Final\n",
    "## Leonardo Augusto Ferreira\n",
    "### leauferreira@cpdee.ufmg.br"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b187aa6c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Alunos:\n",
    "### Gabriel Camatta Zanotelli - 2018020140\n",
    "### Lucas de Almeida Martins - 2018020328"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1b620e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Anaconda\n",
    "# !conda install gplearn\n",
    "# !conda install eckity\n",
    "# !conda install pmlb\n",
    "\n",
    "# python - jupyter nootebook - colab\n",
    "# !pip install gplearn\n",
    "# !pip install eckity\n",
    "# !pip install pmlb\n",
    "\n",
    "\n",
    "# documentation:\n",
    "# https://docs.sympy.org/latest/install.html\n",
    "# https://github.com/EC-KitY/EC-KitY\n",
    "# https://epistasislab.github.io/pmlb/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pmlb import fetch_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from eckity.algorithms.simple_evolution import SimpleEvolution\n",
    "from eckity.sklearn_compatible.sk_classifier import SKClassifier\n",
    "from eckity.breeders.simple_breeder import SimpleBreeder\n",
    "from eckity.creators.gp_creators.ramped_hh import RampedHalfAndHalfCreator\n",
    "from eckity.genetic_encodings.gp.tree.functions import f_add, f_mul, f_sub, f_div, f_neg, f_sqrt, f_log, f_abs, f_inv, f_max, \\\n",
    "    f_min\n",
    "from eckity.genetic_encodings.gp.tree.utils import create_terminal_set\n",
    "from eckity.genetic_operators.crossovers.subtree_crossover import SubtreeCrossover\n",
    "from eckity.genetic_operators.mutations.subtree_mutation import SubtreeMutation\n",
    "from eckity.genetic_operators.selections.tournament_selection import TournamentSelection\n",
    "from eckity.statistics.best_avg_worst_size_tree_statistics import BestAverageWorstSizeTreeStatistics\n",
    "from eckity.subpopulation import Subpopulation\n",
    "from eckity.termination_checkers.threshold_from_target_termination_checker import ThresholdFromTargetTerminationChecker\n",
    "\n",
    "# Adding your own functions\n",
    "from eckity.sklearn_compatible.classification_evaluator import ClassificationEvaluator\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x, y = fetch_data('breast', return_X_y=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=.7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "terminal_set = create_terminal_set(x_train)\n",
    "# function_set = [f_add, f_mul, f_sub, f_div, f_sqrt, f_log, f_abs, f_neg, f_inv, f_max, f_min]\n",
    "\n",
    "function_set = [f_add, f_mul, f_sub, f_div]\n",
    "\n",
    "algo = SimpleEvolution(\n",
    "    Subpopulation(\n",
    "        creators=RampedHalfAndHalfCreator(init_depth=(2, 4),\n",
    "                                                    terminal_set=terminal_set,\n",
    "                                                    function_set=function_set,\n",
    "                                                    bloat_weight=0.0001),\n",
    "        population_size=1000,\n",
    "        evaluator=ClassificationEvaluator(),\n",
    "        higher_is_better=True,\n",
    "        elitism_rate=0.05,\n",
    "        operators_sequence=[\n",
    "            SubtreeCrossover(probability=0.9, arity=2),\n",
    "            SubtreeMutation(probability=0.2, arity=1)\n",
    "        ],\n",
    "        selection_methods=[\n",
    "            # (selection method, selection probability) tuple\n",
    "            (TournamentSelection(tournament_size=4, higher_is_better=True), 1)\n",
    "        ]\n",
    "    ),\n",
    "    breeder=SimpleBreeder(),\n",
    "    max_workers=1,\n",
    "    max_generation=100,\n",
    "\n",
    "    termination_checker=ThresholdFromTargetTerminationChecker(optimal=1, threshold=0.03),\n",
    "    statistics=BestAverageWorstSizeTreeStatistics()\n",
    ")\n",
    "\n",
    "classifier = SKClassifier(algo)\n",
    "\n",
    "classifier.fit(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, classifier.predict(x_test))\n",
    "print(acc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparação de Desempenho entre as Bibliotecas de Programação Genética EC-KitY e GPlearn utilizando Datasets de Regressão e Classificação\n",
    "\n",
    "Para o trabalho final, você deverá utilizar as bibliotecas de programação Genética EC-KitY e GPlearn, juntamente com a biblioteca Penn Machine Learning Benchmarks, a fim de gerar um código Python que realizará testes em três conjuntos de dados para regressão e três conjuntos de dados para classificação. Seu objetivo é comparar as métricas obtidas e determinar qual biblioteca apresenta os melhores resultados.\n",
    "\n",
    "Durante o estudo, você deverá variar as probabilidades de mutação e cruzamento, a fim de identificar a melhor configuração para cada uma das bibliotecas. Registre cuidadosamente os resultados obtidos em relação às métricas avaliadas, considerando medidas como acurácia, precisão, recall, F1-score, erro médio quadrático (RMSE) ou outras relevantes para o problema em questão.\n",
    "\n",
    "Ao final do estudo, apresente uma análise comparativa dos resultados para cada biblioteca, destacando as probabilidades de mutação e cruzamento que produziram os melhores desempenhos. Utilize gráficos, tabelas ou outras visualizações que considerar pertinentes para ilustrar seus resultados e facilitar a compreensão."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Relatório\n",
    "\n",
    "Nesta atividade analisamos a eficiência das bibliotecas de Programação Genética *EC-KitY* e *GPlearn* de forma a fazer uma análise quantitativa da eficiência de ambas, por meio da utilização de diversos conjuntos de dados disponíveis na biblioteca *pmlb*.\n",
    "\n",
    "Esta análise será feita utilizando ambas as bibliotecas para resolução de problemas binários e mono objetivo de quatro conjuntos de dados selecionados, variando dois parâmetros de imensa importância: a probabilidade de mutação e cruzamento. Para cada combinação, serão realizadas diversas iterações, de forma a obter um resultado médio.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dependencias"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from pmlb import fetch_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, mean_squared_log_error\n",
    "from gplearn.genetic import SymbolicRegressor\n",
    "from eckity.algorithms.simple_evolution import SimpleEvolution\n",
    "from eckity.sklearn_compatible.sk_classifier import SKClassifier\n",
    "from eckity.breeders.simple_breeder import SimpleBreeder\n",
    "from eckity.creators.gp_creators.ramped_hh import RampedHalfAndHalfCreator\n",
    "from eckity.genetic_encodings.gp.tree.functions import f_add, f_mul, f_sub, f_div, f_min, f_max, f_sin, f_cos, f_log\n",
    "from eckity.genetic_encodings.gp.tree.utils import create_terminal_set\n",
    "from eckity.genetic_operators.crossovers.subtree_crossover import SubtreeCrossover\n",
    "from eckity.genetic_operators.mutations.subtree_mutation import SubtreeMutation\n",
    "from eckity.genetic_operators.selections.tournament_selection import TournamentSelection\n",
    "from eckity.statistics.best_avg_worst_size_tree_statistics import BestAverageWorstSizeTreeStatistics\n",
    "from eckity.subpopulation import Subpopulation\n",
    "from eckity.termination_checkers.threshold_from_target_termination_checker import ThresholdFromTargetTerminationChecker\n",
    "from eckity.sklearn_compatible.classification_evaluator import ClassificationEvaluator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conjuntos de dados"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "x1, y1 = fetch_data('diabetes', return_X_y=True)\n",
    "x2, y2 = fetch_data('cloud', return_X_y=True)\n",
    "x3, y3 = fetch_data('iris', return_X_y=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Desenvolvimento\n",
    "\n",
    "Para ambas as bibliotecas serão adotados alguns parâmetros padrõesao longo dos testes realizados.\n",
    "- **EC-KitY**\n",
    "    - População máxima de 1000 indivíduos\n",
    "    - Mesmo conjunto de equações para a resolução do problema (adição, subtração, multiplicação, divisão, máximo, mínimo, seno, cosseno, logarítmo)\n",
    "    - Valores base de probabilidade de mutação como 70% e probabilidade de cruzamento e 100%\n",
    "    - Serão testados valores da probabilidade de mutação de 30-90%, com um passo de 20%\n",
    "    - Serão testados valores da probabilidade de cruzamento de 40-100%, com um passo de 20%\n",
    "    - Máximo de 100 gerações\n",
    "    - Para cada caso, serão feitas um número de execuções de garantam uma certa segurança dos resultados. Para essa ativiade, serão feitas 10 iterações\n",
    "\n",
    "- **GPLearn**\n",
    "    - População máxima de 1000 indivíduos\n",
    "    - Mesmo conjunto de equações para a resolução do problema (adição, subtração, multiplicação, divisão, máximo, mínimo, seno, cosseno, logarítmo)\n",
    "    - Como a biblioteca exige que a somatória das probabilidade de corssover e mutações (*Subtree*, *hois* e *point*) tenham uma somatória total de 1, o programa será executado 4 vezes, sempre com a probabilidade iguais dos três tipos de mutação. As configurações são:\n",
    "        - Probabilidade de corssover de 90%; probabilidade de mutação de 3,33%\n",
    "        - Probabilidade de corssover de 80%; probabilidade de mutação de 6,67%\n",
    "        - Probabilidade de corssover de 70%; probabilidade de mutação de 10%\n",
    "        - Probabilidade de corssover de 60%; probabilidade de mutação de 13,33%\n",
    "    - Máximo de 100 gerações\n",
    "    - Para cada caso, serão feitas um número de execuções de garantam uma certa segurança dos resultados. Para essa ativiade, serão feitas 10 iterações"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set-up"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "function_set_ec_kity = [f_add, f_mul, f_sub, f_div, f_min, f_max, f_sin, f_cos, f_log]\n",
    "function_set_gp_learn = ['add', 'sub', 'mul', 'div', 'min', 'max', 'sin', 'cos', 'log']\n",
    "mutation_vec  = [0.3, 0.5, 0.7, 0.9]\n",
    "crossover_vec = [0.4, 0.6, 0.8, 1]\n",
    "iterations = 10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### EC-KitY"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def ec_kity(x, y, _mutation = 0.7, _crossover =1, _higher_is_better = True, _populationSize = 1000, _generationsMax = 100, _average=\"binary\"):\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y,)\n",
    "    terminal_set = create_terminal_set(x_train)\n",
    "\n",
    "    algo = SimpleEvolution(\n",
    "        Subpopulation(\n",
    "            creators=RampedHalfAndHalfCreator(init_depth=(2, 4),\n",
    "                                                        terminal_set=terminal_set,\n",
    "                                                        function_set=function_set_ec_kity,\n",
    "                                                        bloat_weight=0.0001),\n",
    "            population_size=_populationSize,\n",
    "            evaluator=ClassificationEvaluator(),\n",
    "            higher_is_better=_higher_is_better,\n",
    "            elitism_rate=0.05,\n",
    "            operators_sequence=[\n",
    "                SubtreeCrossover(probability=_mutation, arity=2),\n",
    "                SubtreeMutation(probability=_crossover, arity=1)\n",
    "            ],\n",
    "            selection_methods=[\n",
    "                # (selection method, selection probability) tuple\n",
    "                (TournamentSelection(tournament_size=4, higher_is_better=True), 1)\n",
    "            ]\n",
    "        ),\n",
    "        breeder=SimpleBreeder(),\n",
    "        max_workers=1,\n",
    "        max_generation=_generationsMax,\n",
    "\n",
    "        termination_checker=ThresholdFromTargetTerminationChecker(optimal=1, threshold=0.03),\n",
    "        statistics=BestAverageWorstSizeTreeStatistics()\n",
    "    )\n",
    "\n",
    "    classifier = SKClassifier(algo)\n",
    "\n",
    "    classifier.fit(x_train, y_train)\n",
    "\n",
    "    acc =accuracy_score(y_test, classifier.predict(x_test))\n",
    "    f1 = f1_score(y_test, classifier.predict(x_test), average=_average)\n",
    "    rec = recall_score(y_test, classifier.predict(x_test), average=_average)\n",
    "    msle = mean_squared_log_error(y_test, classifier.predict(x_test))\n",
    "\n",
    "    print(\"Acuracia: \", acc)\n",
    "    print(\"F1: \", f1)\n",
    "    print(\"Recall: \", rec)\n",
    "    print(\"RMSE: \", msle)\n",
    "\n",
    "    return [acc, f1, rec, msle]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GPLearn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def gp_learn(x, y, _mutation = 0.1, _crossover = 0.7, _higher_is_better = True, _populationSize = 1000, _generationsMax = 100, _average=\"binary\"):\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "    gplearn_model = SymbolicRegressor(population_size=_populationSize,\n",
    "                                      generations=_generationsMax,\n",
    "                                      function_set=function_set_gp_learn,\n",
    "                                      stopping_criteria=0.03,\n",
    "                                      tournament_size=4,\n",
    "                                      p_crossover=_crossover,\n",
    "                                      p_subtree_mutation=_mutation,\n",
    "                                      p_hoist_mutation=_mutation,\n",
    "                                      p_point_mutation=_mutation,\n",
    "                                      metric='mean absolute error',\n",
    "                                      verbose=1,\n",
    "                                      parsimony_coefficient=0.01)\n",
    "\n",
    "    gplearn_model.fit(x_train, y_train)\n",
    "    y_pred = gplearn_model.predict(x_test)\n",
    "\n",
    "    acc =accuracy_score(y_test, y_pred.round().astype(int))\n",
    "    f1 = f1_score(y_test, y_pred.round().astype(int), average=_average)\n",
    "    rec = recall_score(y_test, y_pred.round().astype(int), average=_average)\n",
    "    msle = mean_squared_log_error(y_test, y_pred.round().astype(int))\n",
    "\n",
    "    print(\"Acuracia: \", acc)\n",
    "    print(\"F1: \", f1)\n",
    "    print(\"Recall: \", rec)\n",
    "    print(\"RMSE: \", msle)\n",
    "\n",
    "    return [acc, f1, rec, msle]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Execução"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "diabetes_ec_kity_cross_results = []; diabetes_ec_kity_mutt_results  = []\n",
    "diabetes_gp_learn_cross_results = []; diabetes_gp_learn_mutt_results  = []\n",
    "\n",
    "for cross in crossover_vec:\n",
    "    diabetes_ec_kity_cross_results.append([ec_kity(x1, y1, _crossover=cross, _higher_is_better=True) for _ in range(iterations)])\n",
    "for mut in mutation_vec:\n",
    "    diabetes_ec_kity_mutt_results.append( [ec_kity(x1, y1, _mutation=mut, _higher_is_better=True) for _ in range(iterations)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cloud_ec_kity_cross_results = []; cloud_ec_kity_mutt_results  = []\n",
    "cloud_gp_learn_cross_results = []; cloud_gp_learn_mutt_results  = []\n",
    "\n",
    "for cross in crossover_vec:\n",
    "    cloud_ec_kity_cross_results.append([ec_kity(x2, y2, _crossover=cross, _higher_is_better=False) for _ in range(iterations)])\n",
    "for mut in mutation_vec:\n",
    "    cloud_ec_kity_mutt_results.append( [ec_kity(x2, y2, _mutation=mut, _higher_is_better=False) for _ in range(iterations)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "iris_ec_kity_cross_results = []; iris_ec_kity_mutt_results  = []\n",
    "iris_gp_learn_cross_results = []; iris_gp_learn_mutt_results  = []\n",
    "\n",
    "for cross in crossover_vec:\n",
    "    iris_ec_kity_cross_results.append([ec_kity(x3, y3, _crossover=cross, _higher_is_better=True) for _ in range(iterations)])\n",
    "for mut in mutation_vec:\n",
    "    iris_ec_kity_mutt_results.append( [ec_kity(x3, y3, _mutation=mut, _higher_is_better=True) for _ in range(iterations)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Resultados das Execuções\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## EC Kity\n",
    "---\n",
    "### Variação do Crossover\n",
    "| Métrica       |  Prob. de Crossover  | Diabetes              | Cloud               | Iris                 |\n",
    "|:--------------|:--------------------:|-----------------------|---------------------|----------------------|\n",
    "| **Acuracia**  |         40%          | 0.6875                | 0.2222222222222222  | 0.631578947368421    |\n",
    "|               |         60%          | 0.6354166666666666    | 0.2222222222222222  | 0.631578947368421    |\n",
    "|               |         80%          | 0.6614583333333334    | 0.3333333333333333  | 0.7105263157894737   |\n",
    "|               |         100%         | 0.6666666666666666    | 0.37037037037037035 | 0.631578947368421    |\n",
    "| **F1**        |         40%          | 0.8148148148148148    | 0.11991711991711991 | 0.511842105263158    |\n",
    "|               |         60%          | 0.7770700636942676    | 0.15959595959595962 | 0.5279605263157895   |\n",
    "|               |         80%          | 0.7962382445141065    | 0.24603174603174605 | 0.6028151774785802   |\n",
    "|               |         100%         | 0.8                   | 0.22866344605475042 | 0.5152354570637119   |\n",
    "| **Recall**    |         40%          | 1.0                   | 0.2222222222222222  | 0.631578947368421    |\n",
    "|               |         60%          | 1.0                   | 0.2222222222222222  | 0.631578947368421    |\n",
    "|               |         80%          | 1.0                   | 0.3333333333333333  | 0.7105263157894737   |\n",
    "|               |         100%         | 1.0                   | 0.37037037037037035 | 0.631578947368421    |\n",
    "| **RMSE**      |         40%          | 0.05137561059161424   | 0.888038084024321   | 0.06056914090800835  |\n",
    "|               |         60%          | 0.059938212356883264  | 0.6032837055643817  | 0.06056914090800835  |\n",
    "|               |         80%          | 0.05565691147424875   | 0.4605378919476176  | 0.04759003928486371  |\n",
    "|               |         100%         | 0.054800651297721846  | 0.7078889947678819  | 0.06056914090800835  |\n",
    "\n",
    "\n",
    "---\n",
    "### Variação da Mutação\n",
    "| Métrica       | Prob. de Mutação  | Diabetes             | Cloud               | Iris                 |\n",
    "|:--------------|:-----------------:|----------------------|---------------------|----------------------|\n",
    "| **Acuracia**  |        30%        | 0.6666666666666666   | 0.4444444444444444  | 0.6578947368421053   |\n",
    "|               |        50%        | 0.7135416666666666   | 0.18518518518518517 | 0.6578947368421053   |\n",
    "|               |        70%        | 0.6510416666666666   | 0.4074074074074074  | 0.6842105263157895   |\n",
    "|               |        90%        | 0.6302083333333334   | 0.37037037037037035 | 0.5789473684210527   |\n",
    "| **F1**        |        30%        | 0.8                  | 0.3440962329851218  | 0.5503759398496241   |\n",
    "|               |        50%        | 0.8328267477203648   | 0.13001101788287142 | 0.5585738539898133   |\n",
    "|               |        70%        | 0.7886435331230284   | 0.31465653687875905 | 0.5789473684210527   |\n",
    "|               |        90%        | 0.7731629392971245   | 0.26492374727668844 | 0.45706371191135736  |\n",
    "| **Recall**    |        30%        | 1.0                  | 0.4444444444444444  | 0.6578947368421053   |\n",
    "|               |        50%        | 1.0                  | 0.18518518518518517 | 0.6578947368421053   |\n",
    "|               |        70%        | 1.0                  | 0.4074074074074074  | 0.6842105263157895   |\n",
    "|               |        90%        | 1.0                  | 0.37037037037037035 | 0.5789473684210527   |\n",
    "| **RMSE**      |        30%        | 0.054800651297721846 | 0.5346983748746058  | 0.05624277370029348  |\n",
    "|               |        50%        | 0.04709430970897971  | 0.6506198938454402  | 0.05624277370029348  |\n",
    "|               |        70%        | 0.05736943182730255  | 0.38979051403507503 | 0.05191640649257859  |\n",
    "|               |        90%        | 0.06079447253341017  | 0.6506198938454402  | 0.06922187532343811  |\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GP-Learn\n",
    "\n",
    "| Métrica       | Prob. Crossover - Mutação | Diabetes              | Cloud               | Iris                  |\n",
    "|:--------------|:-------------------------:|-----------------------|---------------------|-----------------------|\n",
    "| **Acuracia**  |        90% - 3,33%        | 0.6979166666666666    | 0.2222222222222222  | 0.9473684210526315    |\n",
    "|               |        80% - 6,67%        | 0.6354166666666666    | 0.2962962962962963  | 0.9473684210526315    |\n",
    "|               |         70% - 10%         | 0.6822916666666666    | 0.2222222222222222  | 0.9473684210526315    |\n",
    "|               |       60% - 13,33%        | 0.7291666666666666    | 0.37037037037037035 | 0.9736842105263158    |\n",
    "| **F1**        |        90% - 3,33%        | 0.8220858895705522    | 0.0808080808080808  | 0.9475748194014448    |\n",
    "|               |        80% - 6,67%        | 0.7770700636942676    | 0.13544973544973546 | 0.9478810663021191    |\n",
    "|               |         70% - 10%         | 0.8111455108359134    | 0.16083676268861455 | 0.9463241436925646    |\n",
    "|               |       60% - 13,33%        | 0.8433734939759037    | 0.30310770540655596 | 0.9737844611528822    |\n",
    "| **Recall**    |        90% - 3,33%        | 1.0                   | 0.2222222222222222  | 0.9473684210526315    |\n",
    "|               |        80% - 6,67%        | 1.0                   | 0.2962962962962963  | 0.9473684210526315    |\n",
    "|               |         70% - 10%         | 1.0                   | 0.2222222222222222  | 0.9473684210526315    |\n",
    "|               |       60% - 13,33%        | 1.0                   | 0.37037037037037035 | 0.9736842105263158    |\n",
    "| **RMSE**      |        90% - 3,33%        | 0.049663090238560414  | 0.35027448786045023 | 0.008652734415429764  |\n",
    "|               |        80% - 6,67%        | 0.05993821235688327   | 0.25615740163965095 | 0.008652734415429764  |\n",
    "|               |         70% - 10%         | 0.05223187076814113   | 0.2510545770973014  | 0.008652734415429764  |\n",
    "|               |       60% - 13,33%        | 0.044525529179399004  | 0.3965889178397278  | 0.004326367207714882  |"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    15.06      7.43578e+06        5         0.364583              N/A      1.55m\n",
      "   1     9.95          523.575        5         0.364583              N/A      1.15m\n",
      "   2     8.58          96.1453        7         0.364583              N/A      1.07m\n",
      "   3     7.38          37.6052        5         0.363021              N/A     55.53s\n",
      "   4     6.61          22.1851        5         0.363021              N/A     54.97s\n",
      "   5     6.03          20.6856        5         0.363021              N/A     52.48s\n",
      "   6     5.33          49.2165        5         0.363021              N/A     52.08s\n",
      "   7     4.64          32.4855        6         0.363021              N/A     53.26s\n",
      "   8     3.54          9.29339        6         0.363021              N/A     51.10s\n",
      "   9     2.77          3.30976        6         0.363021              N/A     46.88s\n",
      "  10     2.39          3.63777        3         0.364583              N/A     45.76s\n",
      "  11     1.69           4.4419        3         0.364583              N/A     45.16s\n",
      "  12     1.24          30.7458        3         0.364583              N/A     43.26s\n",
      "  13     1.19          10.0236        2         0.366692              N/A     45.31s\n",
      "  14     1.34          3.79186        2         0.366692              N/A     43.60s\n",
      "  15     1.61          13.5793        2         0.366692              N/A     43.74s\n",
      "  16     2.07          1.39042        2         0.366692              N/A     46.55s\n",
      "  17     2.12          3.61791        2         0.366692              N/A     46.72s\n",
      "  18     2.10          1.92309        2         0.366692              N/A      1.80m\n",
      "  19     2.13          8.00201        2         0.366692              N/A     46.68s\n",
      "  20     2.17          25.1237        2         0.366692              N/A     42.65s\n",
      "  21     2.12          103.388        2         0.366692              N/A     41.43s\n",
      "  22     2.12           13.536        2         0.366692              N/A     42.55s\n",
      "  23     2.07          1.80459        2         0.366642              N/A     41.48s\n",
      "  24     2.10          7.45196        4         0.365933              N/A     41.88s\n",
      "  25     2.09          21.5879        2         0.366642              N/A     41.07s\n",
      "  26     2.09          1.26667        2         0.366642              N/A     42.28s\n",
      "  27     2.10          5.35875        2         0.366642              N/A     40.37s\n",
      "  28     2.09          25.6184        2         0.366642              N/A     39.04s\n",
      "  29     2.11          1.69092       14         0.361669              N/A     36.76s\n",
      "  30     2.17          21.3082        2         0.366642              N/A     41.94s\n",
      "  31     2.10          24.4228        7         0.364583              N/A     37.90s\n",
      "  32     2.09          2.07737        2         0.366642              N/A     38.12s\n",
      "  33     2.08           8.3875        2         0.366642              N/A     34.13s\n",
      "  34     2.15          2.83796        3         0.364583              N/A     32.74s\n",
      "  35     2.10          23.4231        2         0.366642              N/A     34.42s\n",
      "  36     2.10          6.06213        4         0.364583              N/A     33.57s\n",
      "  37     2.08          26.9569        2         0.366642              N/A     33.61s\n",
      "  38     2.16           1.1223        2         0.366642              N/A     33.62s\n",
      "  39     2.12          1.52676        2         0.366642              N/A     32.82s\n",
      "  40     2.07          3.51709        2         0.366642              N/A     32.86s\n",
      "  41     2.09          1.20991        2         0.366642              N/A     32.51s\n",
      "  42     2.15          2.08479        2         0.366642              N/A     32.76s\n",
      "  43     2.08          4.12762        2         0.366642              N/A     31.75s\n",
      "  44     2.17          10.6625        2         0.366642              N/A     35.75s\n",
      "  45     2.08          1.07893        2         0.366642              N/A     49.79s\n",
      "  46     2.08          16.9497        2         0.366642              N/A     28.71s\n",
      "  47     2.19          5.46108        2         0.366642              N/A     37.44s\n",
      "  48     2.11          13.3163        2         0.366642              N/A     32.04s\n",
      "  49     2.06          3.57828        2         0.366642              N/A     27.28s\n",
      "  50     2.11          8.26461        2         0.366642              N/A     30.30s\n",
      "  51     2.08          1.91367        3         0.364583              N/A     27.26s\n",
      "  52     2.06          9.54579        2         0.366642              N/A     26.86s\n",
      "  53     2.10          6.21823        2         0.366642              N/A     25.64s\n",
      "  54     2.12          9.96481        2         0.366642              N/A     26.32s\n",
      "  55     2.12          2.49947        2         0.366642              N/A     25.45s\n",
      "  56     2.08           28.303        2         0.366642              N/A     24.75s\n",
      "  57     2.11          22.4864        2         0.366642              N/A     25.14s\n",
      "  58     2.06          3.40208        2         0.366642              N/A     23.41s\n",
      "  59     2.10          13.8026        4         0.364583              N/A     23.07s\n",
      "  60     2.03          8.73365        2         0.364676              N/A     22.18s\n",
      "  61     2.10          12.4481        2         0.364676              N/A     21.22s\n",
      "  62     2.13          6.13403        2         0.364676              N/A     22.35s\n",
      "  63     2.07          4.67067        2         0.364676              N/A     21.66s\n",
      "  64     2.10          1.53941        2         0.364676              N/A     20.54s\n",
      "  65     2.04          11.2239        2         0.364676              N/A     20.21s\n",
      "  66     2.15          1.34812        2         0.364676              N/A     18.94s\n",
      "  67     2.11          2.67185        2         0.364676              N/A     18.56s\n",
      "  68     2.08          6.37245        2         0.364676              N/A     17.52s\n",
      "  69     2.08          1.91629        2         0.364676              N/A     17.44s\n",
      "  70     2.06          2.51897        2         0.364676              N/A     16.73s\n",
      "  71     2.08          2.26758        2         0.364676              N/A     15.18s\n",
      "  72     2.08         0.925414        2         0.364676              N/A     15.39s\n",
      "  73     2.04          3.38491        3         0.364583              N/A     14.37s\n",
      "  74     2.08          32.6507        2         0.364676              N/A     14.53s\n",
      "  75     2.03         0.979972        2         0.364676              N/A     15.40s\n",
      "  76     2.08          45.3837        2         0.364676              N/A     21.57s\n",
      "  77     2.06          4.80007        3         0.364583              N/A     13.30s\n",
      "  78     2.06          3.69752        2         0.364676              N/A     12.05s\n",
      "  79     2.06           2.0949        2         0.364676              N/A     11.34s\n",
      "  80     2.21          8.04559        2         0.364676              N/A     10.86s\n",
      "  81     2.07          1.38863        3         0.364583              N/A     10.13s\n",
      "  82     2.06          4.84448        2         0.364676              N/A      9.49s\n",
      "  83     2.07         0.834314        2         0.364676              N/A     28.83s\n",
      "  84     2.15          413.607        2         0.364676              N/A     46.33s\n",
      "  85     2.12         0.846685        2         0.364676              N/A      8.91s\n",
      "  86     2.08            7.693        2         0.364676              N/A      8.96s\n",
      "  87     2.07          1.78418        2         0.364676              N/A      8.47s\n",
      "  88     2.08          11.0534        2         0.364676              N/A      8.12s\n",
      "  89     2.11          14.9365        2         0.364676              N/A      7.00s\n",
      "  90     2.08          7.60461        4         0.364583              N/A      5.99s\n",
      "  91     2.07          664.039        2         0.364676              N/A      5.44s\n",
      "  92     2.08          1.83555        2         0.364676              N/A      4.65s\n",
      "  93     2.05          8.37285        2         0.364676              N/A      3.86s\n",
      "  94     2.06          4.58649        3         0.364583              N/A      3.78s\n",
      "  95     2.17          1.33913        2         0.364676              N/A      2.39s\n",
      "  96     2.17          58.9664        2         0.364676              N/A      2.10s\n",
      "  97     2.09         0.956983        2          0.36464              N/A      1.29s\n",
      "  98     2.05          1.05643        2          0.36464              N/A      0.70s\n",
      "  99     2.06          2.07787        3         0.364583              N/A      0.00s\n",
      "Acuracia:  0.6979166666666666\n",
      "F1:  0.8220858895705522\n",
      "Recall:  1.0\n",
      "RMSE:  0.049663090238560414\n",
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    15.93          25072.3        5          0.34375              N/A      1.17m\n",
      "   1    11.19          60.0744        3          0.34375              N/A      1.12m\n",
      "   2     8.84           69.696        3          0.34375              N/A      1.15m\n",
      "   3     7.28          13.1021        4          0.34375              N/A      1.20m\n",
      "   4     6.41          34.0598       12          0.34375              N/A      1.09m\n",
      "   5     6.11          18.4159        3          0.34375              N/A      1.10m\n",
      "   6     5.59          14.8773        3          0.34375              N/A      1.05m\n",
      "   7     4.79          17.2017       14         0.339999              N/A      1.05m\n",
      "   8     3.94          8.80096        6         0.342636              N/A     58.99s\n",
      "   9     3.24          648.388        5         0.343231              N/A      1.04m\n",
      "  10     2.77          16.3174        3          0.34375              N/A     57.10s\n",
      "  11     2.40          29.2613        3          0.34375              N/A     53.78s\n",
      "  12     2.28          3.49044        3          0.34375              N/A      1.48m\n",
      "  13     2.16          17.1059        2         0.343811              N/A      1.01m\n",
      "  14     2.19          14.5786        2         0.343811              N/A     52.37s\n",
      "  15     2.17          2.76832        2         0.343811              N/A     49.50s\n",
      "  16     2.13          18.1045        3          0.34375              N/A     52.58s\n",
      "  17     2.22          5.78277        2         0.343811              N/A     54.37s\n",
      "  18     2.20          29.8488        3          0.34375              N/A     54.24s\n",
      "  19     2.22            10.36        2         0.343811              N/A     53.01s\n",
      "  20     2.25          24.5575        2         0.343811              N/A     55.94s\n",
      "  21     2.17          6.62544        3          0.34375              N/A     45.20s\n",
      "  22     2.20          11.0158        2         0.343811              N/A     46.53s\n",
      "  23     2.20          20.0204        2         0.343811              N/A     45.23s\n",
      "  24     2.26          25.4304        2         0.343811              N/A     48.02s\n",
      "  25     2.28          726.667        3          0.34375              N/A     45.23s\n",
      "  26     2.17          29.0284        2         0.343811              N/A     47.39s\n",
      "  27     2.20          23.7985        2         0.343811              N/A     49.83s\n",
      "  28     2.20          6.55816        2         0.343811              N/A     45.64s\n",
      "  29     2.19          49362.7        2         0.343811              N/A     43.65s\n",
      "  30     2.21          127.379        2         0.343811              N/A     49.48s\n",
      "  31     2.24          13.4702        2         0.343811              N/A     42.50s\n",
      "  32     2.19          8.21343        7          0.34375              N/A     42.99s\n",
      "  33     2.25          15.5786        2         0.343811              N/A     44.15s\n",
      "  34     2.23            10.99        3          0.34375              N/A     40.74s\n",
      "  35     2.18          5.34089        3          0.34375              N/A     42.76s\n",
      "  36     2.27          39.2424        3          0.34375              N/A     43.67s\n",
      "  37     2.13          6.59043        4          0.34375              N/A     41.57s\n",
      "  38     2.17          18.5736        2         0.343811              N/A     40.94s\n",
      "  39     2.23          14.0068        2         0.343811              N/A     59.91s\n",
      "  40     2.17          7.78326        2         0.343811              N/A     39.30s\n",
      "  41     2.21          2.10294        2         0.343811              N/A     37.77s\n",
      "  42     2.18          26.9967        2         0.343811              N/A     38.92s\n",
      "  43     2.25          20.2067        4          0.34375              N/A     33.28s\n",
      "  44     2.29          6.59064        2         0.343811              N/A     35.33s\n",
      "  45     2.16          185.596        2         0.343811              N/A     35.53s\n",
      "  46     2.19          4.48811        2         0.343811              N/A     33.72s\n",
      "  47     2.21          23.0969        2         0.343811              N/A     33.64s\n",
      "  48     2.20          9.91886        2         0.343811              N/A     34.54s\n",
      "  49     2.14          6.04591        3          0.34375              N/A     33.65s\n",
      "  50     2.12          412.178        2         0.343811              N/A     31.10s\n",
      "  51     2.13          1.38967        2         0.343811              N/A     31.69s\n",
      "  52     2.20          17.8425        2         0.343811              N/A     32.53s\n",
      "  53     2.21          24.4115        2         0.343811              N/A     29.69s\n",
      "  54     2.10          18.4359        3          0.34375              N/A     29.53s\n",
      "  55     2.20          32.7993        2         0.343811              N/A     28.90s\n",
      "  56     2.16          17.9274        3          0.34375              N/A     26.88s\n",
      "  57     2.13          1.42901        2         0.343811              N/A     28.03s\n",
      "  58     2.27          15.5629        3          0.34375              N/A     26.93s\n",
      "  59     2.26          7.40609        2         0.343811              N/A     26.37s\n",
      "  60     2.21          29.8794        2         0.343811              N/A     25.72s\n",
      "  61     2.26          14.9577        2         0.343811              N/A     26.99s\n",
      "  62     2.10          2.82075        2         0.343811              N/A     23.25s\n",
      "  63     2.19          9.40287        2         0.343811              N/A     23.82s\n",
      "  64     2.14          6.89968        2         0.343811              N/A     23.86s\n",
      "  65     2.20          6.18268        2         0.343811              N/A     24.19s\n",
      "  66     2.16           10.073        8          0.34375              N/A     22.14s\n",
      "  67     2.24          5.72104        2         0.343811              N/A     22.02s\n",
      "  68     2.13          47.4178        2         0.343811              N/A     21.98s\n",
      "  69     2.19          32.0935        2         0.343811              N/A     32.27s\n",
      "  70     2.17          36.5732        2         0.343811              N/A     18.69s\n",
      "  71     2.26          17.2781        2         0.343811              N/A     19.64s\n",
      "  72     2.23          10.5163        2         0.343811              N/A     19.39s\n",
      "  73     2.15          218.199        6          0.34375              N/A     17.72s\n",
      "  74     2.11          5.54484        6          0.34375              N/A     17.26s\n",
      "  75     2.21          44541.1        2         0.343811              N/A     16.95s\n",
      "  76     2.16          7.30522        3          0.34375              N/A     14.18s\n",
      "  77     2.17          14.7554        2         0.343811              N/A     15.52s\n",
      "  78     2.23           15.918        3          0.34375              N/A     15.50s\n",
      "  79     2.25           3.3949        2         0.343811              N/A     13.08s\n",
      "  80     2.25          23.9285        3          0.34375              N/A     12.87s\n",
      "  81     2.16          13672.6        3          0.34375              N/A     12.17s\n",
      "  82     2.23          5.84224        2         0.343811              N/A     11.54s\n",
      "  83     2.27           73.694        2         0.343811              N/A     10.88s\n",
      "  84     2.15          48.9463        2         0.343811              N/A     10.23s\n",
      "  85     2.15          15.2772        2         0.343811              N/A     10.08s\n",
      "  86     2.20          38.6895        2         0.343811              N/A      8.94s\n",
      "  87     2.14          35.7421        2         0.343811              N/A      8.21s\n",
      "  88     2.20           111458        2         0.343811              N/A      7.63s\n",
      "  89     2.24          13.5341        3          0.34375              N/A      7.42s\n",
      "  90     2.17          31.0992        3          0.34375              N/A      6.49s\n",
      "  91     2.17          2.69891        2         0.343811              N/A      5.53s\n",
      "  92     2.12          3.36286        2         0.343811              N/A      4.67s\n",
      "  93     2.12          8.22638        6          0.34375              N/A      4.26s\n",
      "  94     2.20          9.48994        3          0.34375              N/A      3.50s\n",
      "  95     2.16           3.1001        2         0.343811              N/A      2.74s\n",
      "  96     2.23          31.1679        2         0.343811              N/A      2.30s\n",
      "  97     2.23          20.4084        2         0.343811              N/A      1.44s\n",
      "  98     2.27          6.39536        2         0.343811              N/A      0.69s\n",
      "  99     2.15          8000.78        2         0.343811              N/A      0.00s\n",
      "Acuracia:  0.6354166666666666\n",
      "F1:  0.7770700636942676\n",
      "Recall:  1.0\n",
      "RMSE:  0.05993821235688327\n",
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    15.97           560620        3         0.359375              N/A      1.35m\n",
      "   1    10.25          94.8905       12         0.359375              N/A      1.14m\n",
      "   2     8.08          55.7255        4         0.358898              N/A      1.11m\n",
      "   3     6.93          43.3312       18         0.356962              N/A      1.16m\n",
      "   4     6.51          17.1016       13         0.345665              N/A      1.45m\n",
      "   5     5.92          226.604       13         0.345665              N/A      1.08m\n",
      "   6     4.69          14.9545       13         0.345665              N/A      1.02m\n",
      "   7     3.30          11.7827        3         0.359375              N/A      1.08m\n",
      "   8     2.41          6.39259        3         0.359375              N/A     54.15s\n",
      "   9     2.34          4.14979        3         0.359375              N/A     54.10s\n",
      "  10     2.27          128.207        3         0.359375              N/A     54.76s\n",
      "  11     2.35          17.7798        2         0.359401              N/A     55.16s\n",
      "  12     2.35           44.434        3         0.359375              N/A     54.55s\n",
      "  13     2.17          4.81132        2         0.359401              N/A     53.91s\n",
      "  14     2.33          290.433        3         0.359375              N/A     50.58s\n",
      "  15     2.22          10.2463        2         0.359401              N/A     50.06s\n",
      "  16     2.24          262.739        2         0.359401              N/A     53.13s\n",
      "  17     2.25          25.0568        2         0.359401              N/A     53.30s\n",
      "  18     2.30          29.9958        3         0.359375              N/A     54.66s\n",
      "  19     2.42          19.8127        5         0.359375              N/A     54.15s\n",
      "  20     2.28          36.0572        3         0.359375              N/A     51.03s\n",
      "  21     2.25          13.6455        3         0.359375              N/A     48.95s\n",
      "  22     2.20          795.016        3         0.359375              N/A     45.90s\n",
      "  23     2.42          35.3723        2         0.359401              N/A     49.74s\n",
      "  24     2.24          17.3593        2         0.359401              N/A     50.03s\n",
      "  25     2.23          43.5307        2         0.359401              N/A     47.17s\n",
      "  26     2.29          172.372        2         0.359401              N/A     42.93s\n",
      "  27     2.28          12.4226        4         0.359375              N/A     47.52s\n",
      "  28     2.38          549.022        2         0.359401              N/A     46.51s\n",
      "  29     2.22           203.45        2         0.359401              N/A     42.42s\n",
      "  30     2.25          9.40501        2         0.359401              N/A     43.27s\n",
      "  31     2.29          6.75192        3         0.359375              N/A      1.07m\n",
      "  32     2.27          33.8327        3         0.359375              N/A     42.48s\n",
      "  33     2.29          27.5197        3         0.359375              N/A     44.91s\n",
      "  34     2.40          1818.25        3         0.359375              N/A     44.95s\n",
      "  35     2.34          10944.3        2         0.359401              N/A     40.17s\n",
      "  36     2.16          6.87778        4         0.359375              N/A     39.26s\n",
      "  37     2.34          5.00406        2         0.359401              N/A     39.34s\n",
      "  38     2.22          66.3708        2         0.359401              N/A     36.40s\n",
      "  39     2.28          20.7992        2         0.359401              N/A     37.23s\n",
      "  40     2.23          7.16079        2         0.359401              N/A     41.35s\n",
      "  41     2.36          21.2563        2         0.359401              N/A     36.10s\n",
      "  42     2.27          32.1148        2         0.359401              N/A     36.38s\n",
      "  43     2.19          26.1476        2         0.359401              N/A     37.03s\n",
      "  44     2.25          11.3777        2         0.359401              N/A     35.14s\n",
      "  45     2.23          12.5554        2         0.359401              N/A     32.32s\n",
      "  46     2.24          24.4099        5         0.359375              N/A     33.74s\n",
      "  47     2.39          58.3428        7         0.359375              N/A     32.64s\n",
      "  48     2.22          9.97176       15         0.359375              N/A     32.12s\n",
      "  49     2.20          37.9059        2         0.359401              N/A     33.80s\n",
      "  50     2.30          9.78407        4         0.359375              N/A     32.01s\n",
      "  51     2.25           18.188        2         0.359401              N/A     40.44s\n",
      "  52     2.28          69.2033        2         0.359401              N/A     30.99s\n",
      "  53     2.21          53.0975        2         0.359401              N/A     29.36s\n",
      "  54     2.31          105.225        2         0.359401              N/A     29.67s\n",
      "  55     2.31           34.179        3         0.359375              N/A     27.03s\n",
      "  56     2.25          27.9715        2         0.359401              N/A     29.67s\n",
      "  57     2.27          86.3579        3         0.359375              N/A     27.99s\n",
      "  58     2.34          5.13591        3         0.359375              N/A     27.12s\n",
      "  59     2.36          18.3837        3         0.359375              N/A     23.24s\n",
      "  60     2.31          21.4625        6         0.359375              N/A     39.53s\n",
      "  61     2.36          33.9519        2         0.359401              N/A     25.16s\n",
      "  62     2.20          43.1999        5         0.359375              N/A     23.54s\n",
      "  63     2.44          21.3795        7         0.359375              N/A     23.63s\n",
      "  64     2.28          8.94649        3         0.359401              N/A     22.31s\n",
      "  65     2.34          10.5381        4         0.359375              N/A     24.39s\n",
      "  66     2.24          50.8226        3         0.359375              N/A     20.65s\n",
      "  67     2.22           47.192        2         0.359401              N/A     22.22s\n",
      "  68     2.27          18.5136        3         0.359375              N/A     21.42s\n",
      "  69     2.25          6.75976        2         0.359401              N/A     20.32s\n",
      "  70     2.33          42.4357        4         0.359375              N/A     18.65s\n",
      "  71     2.25          32.1726        2         0.359401              N/A     18.98s\n",
      "  72     2.30          20.0018        2         0.359401              N/A     18.41s\n",
      "  73     2.36          1678.47        3         0.359375              N/A     16.69s\n",
      "  74     2.30          22.9685        3         0.359375              N/A     16.88s\n",
      "  75     2.19          10.1511        2         0.359401              N/A     16.18s\n",
      "  76     2.21          15.3581        3         0.359375              N/A     15.47s\n",
      "  77     2.39          23.6653        2         0.359401              N/A     14.83s\n",
      "  78     2.28          23016.6        2         0.359401              N/A     14.14s\n",
      "  79     2.32          12.6597        2         0.359393              N/A     12.76s\n",
      "  80     2.33          72.0442        3         0.359375              N/A     13.87s\n",
      "  81     2.28          7.38806        3         0.359375              N/A     12.60s\n",
      "  82     2.34          42.4226        2         0.359393              N/A     11.97s\n",
      "  83     2.30            12.01        7         0.359375              N/A     10.82s\n",
      "  84     2.28          19.2567        5          0.35808              N/A     10.52s\n",
      "  85     2.31          27.3204        2         0.359393              N/A      9.19s\n",
      "  86     2.30          10.4398        3         0.359375              N/A      8.52s\n",
      "  87     2.18          51.3734        3         0.359375              N/A      8.33s\n",
      "  88     2.31          70.7378       12         0.359375              N/A      7.63s\n",
      "  89     2.30          23.4356        2         0.359393              N/A      7.02s\n",
      "  90     2.35          16.4013        3         0.359375              N/A      6.40s\n",
      "  91     2.33          38.0958        2         0.359393              N/A      5.47s\n",
      "  92     2.24          244.529        3         0.359375              N/A      4.71s\n",
      "  93     2.23          845.724        3         0.359375              N/A      4.34s\n",
      "  94     2.36          251.345        2         0.359393              N/A      3.65s\n",
      "  95     2.41           5.1207        2         0.359393              N/A      4.46s\n",
      "  96     2.25          67.9097        2         0.359393              N/A      2.02s\n",
      "  97     2.27          6.86768        3         0.359375              N/A      1.33s\n",
      "  98     2.26          22.9334        2         0.359393              N/A      0.70s\n",
      "  99     2.21          17.8731        3         0.359375              N/A      0.00s\n",
      "Acuracia:  0.6822916666666666\n",
      "F1:  0.8111455108359134\n",
      "Recall:  1.0\n",
      "RMSE:  0.05223187076814113\n",
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    16.05          30358.1        3            0.375              N/A      1.28m\n",
      "   1    10.82          215.518        3            0.375              N/A      1.09m\n",
      "   2     8.73          49.7032       12            0.375              N/A      1.12m\n",
      "   3     7.53          3355.37       13            0.375              N/A      1.10m\n",
      "   4     7.04          21.1816       12            0.375              N/A      1.15m\n",
      "   5     6.46          26.1838        3            0.375              N/A      1.02m\n",
      "   6     5.35          2127.13       13         0.374353              N/A     58.29s\n",
      "   7     4.22           155896        4            0.375              N/A     59.08s\n",
      "   8     3.46          30.9831        3            0.375              N/A     59.10s\n",
      "   9     2.88          102.935        6         0.373799              N/A     54.21s\n",
      "  10     2.47          568.134        4            0.375              N/A     55.62s\n",
      "  11     2.27          33.3382        3            0.375              N/A     54.79s\n",
      "  12     2.29          25.3657        3            0.375              N/A     52.47s\n",
      "  13     2.27          10.7721        3            0.375              N/A     56.50s\n",
      "  14     2.46          1153.45        3            0.375              N/A     51.79s\n",
      "  15     2.46          19.5801        2         0.375061              N/A     49.08s\n",
      "  16     2.30          5.25816        2         0.375061              N/A     51.39s\n",
      "  17     2.43          46.5796        2         0.375061              N/A     50.03s\n",
      "  18     2.45           151.74        5            0.375              N/A     46.41s\n",
      "  19     2.30          70.7821        2         0.375061              N/A     47.41s\n",
      "  20     2.35          8.07507        2         0.375061              N/A     50.36s\n",
      "  21     2.37          25.2052        3            0.375              N/A     49.50s\n",
      "  22     2.47          20.7213        2         0.375061              N/A     48.67s\n",
      "  23     2.43          35.4493        3            0.375              N/A     47.22s\n",
      "  24     2.50          33.9086        2         0.375061              N/A     48.04s\n",
      "  25     2.34          12.5083        3            0.375              N/A     42.30s\n",
      "  26     2.34          56.5447        3            0.375              N/A     46.83s\n",
      "  27     2.40          13.1987        2         0.375061              N/A     45.52s\n",
      "  28     2.45          78.3037        2         0.375061              N/A     42.57s\n",
      "  29     2.48          2483.11        2         0.375061              N/A     44.77s\n",
      "  30     2.33          85.9545        2         0.375061              N/A     41.46s\n",
      "  31     2.30          63.5917        3            0.375              N/A     40.98s\n",
      "  32     2.28          45.8201        3            0.375              N/A     46.12s\n",
      "  33     2.28          12.7108        3            0.375              N/A     43.44s\n",
      "  34     2.37          39.8289        2         0.375061              N/A     40.27s\n",
      "  35     2.27          3.82057        3            0.375              N/A     56.87s\n",
      "  36     2.41          23.3847        3            0.375              N/A     40.58s\n",
      "  37     2.44          16.3579        3            0.375              N/A     38.31s\n",
      "  38     2.35          115.037        2         0.375061              N/A     40.58s\n",
      "  39     2.32          22.4834        3            0.375              N/A     39.49s\n",
      "  40     2.42          23.6931        3            0.375              N/A     39.97s\n",
      "  41     2.28          69.0095        2         0.375061              N/A     38.57s\n",
      "  42     2.31           6.1565        2         0.375061              N/A     34.44s\n",
      "  43     2.39          24.4742        2         0.375061              N/A     37.20s\n",
      "  44     2.46          98.3965        3            0.375              N/A     36.00s\n",
      "  45     2.24          25.4578        3            0.375              N/A     34.15s\n",
      "  46     2.37          46.1534        2         0.375021              N/A     35.75s\n",
      "  47     2.48          27.4613        3            0.375              N/A     33.51s\n",
      "  48     2.30           58.998        2         0.375021              N/A     31.76s\n",
      "  49     2.26          26.5014        2         0.375021              N/A     33.72s\n",
      "  50     2.56          10.1064       12         0.375015              N/A     32.62s\n",
      "  51     2.36          15.4454        2         0.375021              N/A     30.63s\n",
      "  52     2.52          13.9894        3            0.375              N/A     31.62s\n",
      "  53     2.39          57.3699        3            0.375              N/A     30.64s\n",
      "  54     2.39          61.9297        2         0.375021              N/A     29.64s\n",
      "  55     2.28          42.4083        7         0.374289              N/A     28.22s\n",
      "  56     2.47          44.2357        2         0.375021              N/A     27.99s\n",
      "  57     2.31          235.163        3            0.375              N/A     28.72s\n",
      "  58     2.39          17.9355        3            0.375              N/A     27.82s\n",
      "  59     2.46          54.3697        3            0.375              N/A     27.51s\n",
      "  60     2.37          17.8155        3            0.375              N/A     24.71s\n",
      "  61     2.44          29.9899        7            0.375              N/A     24.10s\n",
      "  62     2.37          14.4829        2         0.375021              N/A     25.26s\n",
      "  63     2.49          79.6186        5         0.374132              N/A     23.53s\n",
      "  64     2.52          190.963        3            0.375              N/A     21.95s\n",
      "  65     2.50          90.1205        4            0.375              N/A     21.32s\n",
      "  66     2.42          22.3231        3            0.375              N/A     33.57s\n",
      "  67     2.46          64.3491        2         0.375021              N/A     22.34s\n",
      "  68     2.30          21.4906        2         0.375021              N/A     19.99s\n",
      "  69     2.31          29.7685        2         0.375021              N/A     18.86s\n",
      "  70     2.32          15.3441        3            0.375              N/A     18.69s\n",
      "  71     2.21          29.7613        3            0.375              N/A     20.41s\n",
      "  72     2.52          24.9278        3            0.375              N/A     20.08s\n",
      "  73     2.38          41.4818        3            0.375              N/A     30.07s\n",
      "  74     2.28          14.6348        3            0.375              N/A     21.97s\n",
      "  75     2.34          33.3455        2         0.375021              N/A     24.64s\n",
      "  76     2.31          78.8007        2         0.375021              N/A     20.74s\n",
      "  77     2.35          19.2318        3            0.375              N/A     16.57s\n",
      "  78     2.42          218.526        2         0.375021              N/A     13.82s\n",
      "  79     2.45          35.7208        2         0.375021              N/A     13.56s\n",
      "  80     2.39          1565.69        2         0.375021              N/A     12.31s\n",
      "  81     2.44          126.111        2         0.375021              N/A     13.04s\n",
      "  82     2.46          88.3771        2         0.375021              N/A     12.45s\n",
      "  83     2.46          1451.84        3            0.375              N/A     11.43s\n",
      "  84     2.34          73.9145        4            0.375              N/A     10.14s\n",
      "  85     2.49          115.706        2         0.375021              N/A      9.92s\n",
      "  86     2.44          164.982        3            0.375              N/A      8.90s\n",
      "  87     2.32           56.279        3            0.375              N/A      8.72s\n",
      "  88     2.36          2160.35        3            0.375              N/A      7.00s\n",
      "  89     2.32          20.8655        6         0.375005              N/A      7.19s\n",
      "  90     2.38          32.7687        4            0.375              N/A      6.63s\n",
      "  91     2.25          24.0497        3            0.375              N/A      5.90s\n",
      "  92     2.47          30.9522        8            0.375              N/A      5.14s\n",
      "  93     2.35          35.6542        3            0.375              N/A      4.49s\n",
      "  94     2.35          32.6567        3            0.375              N/A      3.98s\n",
      "  95     2.35          22.6777        3            0.375              N/A      2.64s\n",
      "  96     2.31          23.4221        4            0.375              N/A      1.98s\n",
      "  97     2.43           16.626        3            0.375              N/A      1.44s\n",
      "  98     2.26          11.6375        2         0.375021              N/A      0.71s\n",
      "  99     2.32          254.019        3            0.375              N/A      0.00s\n",
      "Acuracia:  0.7291666666666666\n",
      "F1:  0.8433734939759037\n",
      "Recall:  1.0\n",
      "RMSE:  0.044525529179399004\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.7291666666666666, 0.8433734939759037, 1.0, 0.044525529179399004]"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_learn(x1, y1, _mutation=.1/3, _crossover=.8, _higher_is_better=True)\n",
    "gp_learn(x1, y1, _mutation=.2/3, _crossover=.8, _higher_is_better=True)\n",
    "gp_learn(x1, y1, _mutation=.3/3, _crossover=.7, _higher_is_better=True)\n",
    "gp_learn(x1, y1, _mutation=.4/3, _crossover=.6, _higher_is_better=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Anotações\n",
    "\n",
    "Bases de dados de classificação tem que ser binaria\n",
    "As de regressão tem que ser mono objetivo\n",
    "\n",
    "Usar a biblioteca \"pmlb\" pra pegar um banco de dados\n",
    "\n",
    "Variar as probabilidades ditas no enunciado\n",
    "\n",
    "Relatorio no markdown\n",
    "\n",
    "Rodar umas 30 (ou 3) vezes pra cada resultado (uma quantidade que de uma certa segurnaça) uma vez que o resultado é probabilistico\n",
    "\n",
    "Pegar uns 3 ou 4 valores diferentes para cada"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}